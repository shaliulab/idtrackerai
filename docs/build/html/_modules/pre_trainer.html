<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-114600635-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    <title>pre_trainer &mdash; idtrackerai v0.0 Manual</title>
    
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-extend.css">
    <link rel="stylesheet" href="../_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="../genindex.html" >
    <link rel="search" title="Search" href="../search.html" >
    <link rel="top" title="idtrackerai v0.0 Manual" href="../index.html" >
    <link rel="up" title="Module code" href="index.html" > 
  </head>
  <body>

<div class="container">
  <div class="top-scipy-org-logo-header">
    <a href="../index.html">
      <img style="border: 0;" alt="idtrackerai" src="../_static/img/idtracker_logo.gif"></a>
    </div>
  </div>
</div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
        <li class="active"><a href="https://gitlab.com/polavieja_lab/idtrackerai.git">GitLab repo</a></li>
	
        <li class="active"><a href="../index.html">idtrackerai v0.0 Manual</a></li>
	
          <li class="active"><a href="index.html" accesskey="U">Module code</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <h1>Source code for pre_trainer</h1><div class="highlight"><pre>
<span></span><span class="c1"># This file is part of idtracker.ai a multiple animals tracking system</span>
<span class="c1"># described in [1].</span>
<span class="c1"># Copyright (C) 2017- Francisco Romero Ferrero, Mattia G. Bergomi,</span>
<span class="c1"># Francisco J.H. Heras, Robert Hinz, Gonzalo G. de Polavieja and the</span>
<span class="c1"># Champalimaud Foundation.</span>
<span class="c1">#</span>
<span class="c1"># idtracker.ai is free software: you can redistribute it and/or modify</span>
<span class="c1"># it under the terms of the GNU General Public License as published by</span>
<span class="c1"># the Free Software Foundation, either version 3 of the License, or</span>
<span class="c1"># (at your option) any later version.</span>
<span class="c1">#</span>
<span class="c1"># This program is distributed in the hope that it will be useful,</span>
<span class="c1"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="c1"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="c1"># GNU General Public License for more details. In addition, we require</span>
<span class="c1"># derivatives or applications to acknowledge the authors by citing [1].</span>
<span class="c1">#</span>
<span class="c1"># You should have received a copy of the GNU General Public License</span>
<span class="c1"># along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.</span>
<span class="c1">#</span>
<span class="c1"># For more information please send an email (idtrackerai@gmail.com) or</span>
<span class="c1"># use the tools available at https://gitlab.com/polavieja_lab/idtrackerai.git.</span>
<span class="c1">#</span>
<span class="c1"># [1] Romero-Ferrero, F., Bergomi, M.G., Hinz, R.C., Heras, F.J.H., De Polavieja, G.G.,</span>
<span class="c1"># (2018). idtracker.ai: Tracking all individuals in large collectives of unmarked animals (R-F.,F. and B.,M. contributed equally to this work.)</span>
 

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">idtrackerai.network.identification_model.network_params</span> <span class="k">import</span> <span class="n">NetworkParams</span>
<span class="kn">from</span> <span class="nn">idtrackerai.network.identification_model.get_data</span> <span class="k">import</span> <span class="n">DataSet</span><span class="p">,</span> <span class="n">split_data_train_and_validation</span>
<span class="kn">from</span> <span class="nn">idtrackerai.network.identification_model.id_CNN</span> <span class="k">import</span> <span class="n">ConvNetwork</span>
<span class="kn">from</span> <span class="nn">idtrackerai.network.identification_model.epoch_runner</span> <span class="k">import</span> <span class="n">EpochRunner</span>
<span class="kn">from</span> <span class="nn">idtrackerai.network.identification_model.stop_training_criteria</span> <span class="k">import</span> <span class="n">Stop_Training</span>
<span class="kn">from</span> <span class="nn">idtrackerai.network.identification_model.store_accuracy_and_loss</span> <span class="k">import</span> <span class="n">Store_Accuracy_and_Loss</span>
<span class="kn">from</span> <span class="nn">idtrackerai.list_of_global_fragments</span> <span class="k">import</span> <span class="n">ListOfGlobalFragments</span>
<span class="kn">from</span> <span class="nn">idtrackerai.constants</span> <span class="k">import</span>  <span class="n">MAX_RATIO_OF_PRETRAINED_IMAGES</span><span class="p">,</span> <span class="n">BATCH_SIZE_IDCNN</span>
<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;idtrackeraiApp.py&#39;</span> <span class="ow">or</span> <span class="s1">&#39;idtrackeraiGUI&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="kn">from</span> <span class="nn">kivy.logger</span> <span class="k">import</span> <span class="n">Logger</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">Logger</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">logging</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;__main__.pre_trainer&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="pre_train_global_fragment"><a class="viewcode-back" href="../fingerprint_protocol_cascade.html#pre_trainer.pre_train_global_fragment">[docs]</a><span class="k">def</span> <span class="nf">pre_train_global_fragment</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
                                <span class="n">pretraining_global_fragment</span><span class="p">,</span>
                                <span class="n">list_of_fragments</span><span class="p">,</span>
                                <span class="n">global_epoch</span><span class="p">,</span>
                                <span class="n">check_for_loss_plateau</span><span class="p">,</span>
                                <span class="n">store_accuracy_and_error</span><span class="p">,</span>
                                <span class="n">save_summaries</span><span class="p">,</span> <span class="n">store_training_accuracy_and_loss_data</span><span class="p">,</span>
                                <span class="n">store_validation_accuracy_and_loss_data</span><span class="p">,</span>
                                <span class="n">print_flag</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="n">plot_flag</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="n">batch_size</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                                <span class="n">canvas_from_GUI</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs pretraining on a single global fragments</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    net : &lt;ConvNetwork obejct&gt;</span>
<span class="sd">        an instance of the class :class:`~idCNN.ConvNetwork`</span>
<span class="sd">    pretraining_global_fragment : &lt;GlobalFragment object&gt;</span>
<span class="sd">        an instance of the class :class:`~globalfragment.GlobalFragment`</span>
<span class="sd">    list_of_fragments : &lt;ListOfFragments object&gt;</span>
<span class="sd">        an instance of the class :class:`~list_of_fragments.ListOfFragments`</span>
<span class="sd">    global_epoch : int</span>
<span class="sd">        global counter of the training epoch in pretraining</span>
<span class="sd">    check_for_loss_plateau : bool</span>
<span class="sd">        if True the stopping criteria (see :mod:`~stop_training_criteria`) will</span>
<span class="sd">        automatically stop the training in case the loss functin computed for</span>
<span class="sd">        the validation set of images reaches a plateau</span>
<span class="sd">    store_accuracy_and_error : bool</span>
<span class="sd">        if True the values of the loss function, accuracy and individual</span>
<span class="sd">        accuracy will be stored</span>
<span class="sd">    save_summaries : bool</span>
<span class="sd">        if True tensorflow summaries will be generated and stored to allow</span>
<span class="sd">        tensorboard visualisation of both loss and activity histograms</span>
<span class="sd">    store_training_accuracy_and_loss_data : &lt;Store_Accuracy_and_Loss object&gt;</span>
<span class="sd">        an instance of the class :class:`~Store_Accuracy_and_Loss`</span>
<span class="sd">    store_validation_accuracy_and_loss_data : &lt;Store_Accuracy_and_Loss object&gt;</span>
<span class="sd">        an instance of the class :class:`~Store_Accuracy_and_Loss`</span>
<span class="sd">    print_flag : bool</span>
<span class="sd">        if True additional information are printed in the terminal</span>
<span class="sd">    plot_flag : bool</span>
<span class="sd">        if True training and validation loss, accuracy and individual accuracy</span>
<span class="sd">        are plot in a graph at the end of the training session</span>
<span class="sd">    batch_size : int</span>
<span class="sd">        size of the batch of images used for training</span>
<span class="sd">    canvas_from_GUI : matplotlib figure canvas</span>
<span class="sd">        canvas of the matplotlib figure initialised in</span>
<span class="sd">        :class:`~tracker.Tracker` used to update the figure in the GUI</span>
<span class="sd">        visualisation of pretraining</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    &lt;ConvNetwork object&gt;</span>
<span class="sd">        network with updated parameters after training</span>
<span class="sd">    float</span>
<span class="sd">        ration of images used for pretraining over the total number of</span>
<span class="sd">        available images</span>
<span class="sd">    int</span>
<span class="sd">        global epoch counter updated after the training session</span>
<span class="sd">    &lt;Store_Accuracy_and_Loss object&gt;</span>
<span class="sd">        updated with the values collected on the training set of labelled</span>
<span class="sd">        images</span>
<span class="sd">    &lt;Store_Accuracy_and_Loss object&gt;</span>
<span class="sd">        updated with the values collected on the validation set of labelled</span>
<span class="sd">        images</span>
<span class="sd">    &lt;ListOfFragments objects&gt;</span>
<span class="sd">        list of instances of the class :class:`~fragment.Fragment`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get images and labels from the current global fragment</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">pretraining_global_fragment</span><span class="o">.</span><span class="n">get_images_and_labels_for_pretraining</span><span class="p">()</span>
    <span class="c1"># Instantiate data_set</span>
    <span class="n">training_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_data_train_and_validation</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">number_of_animals</span><span class="p">,</span>
                                                                            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">training_dataset</span><span class="o">.</span><span class="n">convert_labels_to_one_hot</span><span class="p">()</span>
    <span class="n">validation_dataset</span><span class="o">.</span><span class="n">convert_labels_to_one_hot</span><span class="p">()</span>
    <span class="c1"># Reinitialize softmax and fully connected</span>
    <span class="c1"># (the fully connected layer and the softmax are initialized since the labels</span>
    <span class="c1"># of the images for each pretraining global fragments are different)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">reinitialize_softmax_and_fully_connected</span><span class="p">()</span>
    <span class="c1"># Train network</span>
    <span class="c1">#compute weights to be fed to the loss function (weighted cross entropy)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">compute_loss_weights</span><span class="p">(</span><span class="n">training_dataset</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="c1">#instantiate epochs runners for train and validation</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">EpochRunner</span><span class="p">(</span><span class="n">training_dataset</span><span class="p">,</span>
                        <span class="n">starting_epoch</span> <span class="o">=</span> <span class="n">global_epoch</span><span class="p">,</span>
                        <span class="n">print_flag</span> <span class="o">=</span> <span class="n">print_flag</span><span class="p">,</span>
                        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">validator</span> <span class="o">=</span> <span class="n">EpochRunner</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">,</span>
                        <span class="n">starting_epoch</span> <span class="o">=</span> <span class="n">global_epoch</span><span class="p">,</span>
                        <span class="n">print_flag</span> <span class="o">=</span> <span class="n">print_flag</span><span class="p">,</span>
                        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="c1">#set criteria to stop the training</span>
    <span class="n">stop_training</span> <span class="o">=</span> <span class="n">Stop_Training</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">number_of_animals</span><span class="p">,</span>
                                <span class="n">check_for_loss_plateau</span> <span class="o">=</span> <span class="n">check_for_loss_plateau</span><span class="p">)</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">stop_training</span><span class="p">(</span><span class="n">store_training_accuracy_and_loss_data</span><span class="p">,</span>
                            <span class="n">store_validation_accuracy_and_loss_data</span><span class="p">,</span>
                            <span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span><span class="p">):</span>
        <span class="n">feed_dict_train</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run_epoch</span><span class="p">(</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="n">store_training_accuracy_and_loss_data</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>
        <span class="n">feed_dict_val</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">run_epoch</span><span class="p">(</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span> <span class="n">store_validation_accuracy_and_loss_data</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">validate</span><span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">global_step</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">starting_epoch</span> <span class="o">+</span> <span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">save_summaries</span><span class="p">:</span>
            <span class="n">net</span><span class="o">.</span><span class="n">write_summaries</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">starting_epoch</span> <span class="o">+</span> <span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span><span class="p">,</span><span class="n">feed_dict_train</span><span class="p">,</span> <span class="n">feed_dict_val</span><span class="p">)</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">_epochs_completed</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">pretraining_global_fragment</span><span class="o">.</span><span class="n">update_individual_fragments_attribute</span><span class="p">(</span><span class="s1">&#39;_used_for_pretraining&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plot_flag</span> <span class="ow">and</span> <span class="n">canvas_from_GUI</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">store_training_accuracy_and_loss_data</span><span class="o">.</span><span class="n">plot_global_fragments</span><span class="p">(</span><span class="n">ax_arr</span><span class="p">,</span> <span class="n">video</span><span class="p">,</span> <span class="n">list_of_fragments</span><span class="o">.</span><span class="n">fragments</span><span class="p">,</span> <span class="n">black</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">ax_arr</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span> <span class="c1"># clear bars</span>
        <span class="n">store_training_accuracy_and_loss_data</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax_arr</span><span class="p">,</span> <span class="n">epoch_index_to_plot</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="n">store_validation_accuracy_and_loss_data</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax_arr</span><span class="p">,</span> <span class="n">epoch_index_to_plot</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">epoch_index_to_plot</span> <span class="o">+=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span>
    <span class="k">if</span> <span class="n">store_accuracy_and_error</span><span class="p">:</span>
        <span class="n">store_training_accuracy_and_loss_data</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span><span class="p">)</span>
        <span class="n">store_validation_accuracy_and_loss_data</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span><span class="p">)</span>
    <span class="n">global_epoch</span> <span class="o">+=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">_epochs_completed</span>
    <span class="n">net</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">plot_flag</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">save_folder</span><span class="p">,</span><span class="s1">&#39;pretraining_gf</span><span class="si">%i</span><span class="s1">.pdf&#39;</span><span class="o">%</span><span class="n">i</span><span class="p">))</span>
    <span class="n">ratio_of_pretrained_images</span> <span class="o">=</span> <span class="n">list_of_fragments</span><span class="o">.</span><span class="n">compute_ratio_of_images_used_for_pretraining</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;limit ratio of images to be used during pretraining: </span><span class="si">%.4f</span><span class="s2"> (if higher than </span><span class="si">%.2f</span><span class="s2"> we stop)&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">ratio_of_pretrained_images</span><span class="p">,</span> <span class="n">MAX_RATIO_OF_PRETRAINED_IMAGES</span><span class="p">))</span></div>
    <span class="k">return</span> <span class="n">net</span><span class="p">,</span> <span class="n">ratio_of_pretrained_images</span><span class="p">,</span> <span class="n">global_epoch</span><span class="p">,</span> <span class="n">store_training_accuracy_and_loss_data</span><span class="p">,</span> <span class="n">store_validation_accuracy_and_loss_data</span><span class="p">,</span> <span class="n">list_of_fragments</span>

<div class="viewcode-block" id="pre_train"><a class="viewcode-back" href="../fingerprint_protocol_cascade.html#pre_trainer.pre_train">[docs]</a><span class="k">def</span> <span class="nf">pre_train</span><span class="p">(</span><span class="n">video</span><span class="p">,</span> <span class="n">list_of_fragments</span><span class="p">,</span> <span class="n">list_of_global_fragments</span><span class="p">,</span>
                <span class="n">params</span><span class="p">,</span> <span class="n">store_accuracy_and_error</span><span class="p">,</span>
                <span class="n">check_for_loss_plateau</span><span class="p">,</span> <span class="n">save_summaries</span><span class="p">,</span>
                <span class="n">print_flag</span><span class="p">,</span> <span class="n">plot_flag</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs pretraining by iterating on the list of global fragments</span>
<span class="sd">    sorted by distance travelled, until the threshold</span>
<span class="sd">    :const:`~constants.MAX_RATIO_OF_PRETRAINED_IMAGES` is reached</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    video : &lt;Video object&gt;</span>
<span class="sd">        an instance of the class :class:`~video.Video`</span>
<span class="sd">    list_of_fragments : &lt;ListOfFragments object&gt;</span>
<span class="sd">        an instance of the class :class:`~list_of_fragments.ListOfFragments`</span>
<span class="sd">    list_of_global_fragments : &lt;ListOfGlobalFragments object&gt;</span>
<span class="sd">        an instance of the class</span>
<span class="sd">        :class:`~list_of_global_fragments.ListOfGlobalFragments`</span>
<span class="sd">    params : &lt;NetworkParams object&gt;</span>
<span class="sd">        an instance of the class :class:`~network_params.NetworkParams`</span>
<span class="sd">    store_accuracy_and_error : bool</span>
<span class="sd">        if True the values of the loss function, accuracy and individual</span>
<span class="sd">        accuracy will be stored</span>
<span class="sd">    check_for_loss_plateau : bool</span>
<span class="sd">        if True the stopping criteria (see :mod:`~stop_training_criteria`) will</span>
<span class="sd">        automatically stop the training in case the loss functin computed for</span>
<span class="sd">        the validation set of images reaches a plateau</span>
<span class="sd">    save_summaries : bool</span>
<span class="sd">        if True tensorflow summaries will be generated and stored to allow</span>
<span class="sd">        tensorboard visualisation of both loss and activity histograms</span>
<span class="sd">    print_flag : bool</span>
<span class="sd">        if True additional information are printed in the terminal</span>
<span class="sd">    plot_flag : bool</span>
<span class="sd">        if True training and validation loss, accuracy and individual accuracy</span>
<span class="sd">        are plot in a graph at the end of the training session</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    &lt;ConvNetwork object&gt;</span>
<span class="sd">        an instance of the class :class:`~id_CNN.ConvNetwork`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#initialize global epoch counter that takes into account all the steps in the pretraining</span>
    <span class="n">global_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">number_of_images_used_during_pretraining</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1">#initialize network</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">ConvNetwork</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">video</span><span class="o">.</span><span class="n">tracking_with_knowledge_transfer</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">restore</span><span class="p">()</span>
    <span class="c1">#instantiate objects to store loss and accuracy values for training and validation</span>
    <span class="c1">#(the loss and accuracy of the validation are saved to allow the automatic stopping of the training)</span>
    <span class="n">store_training_accuracy_and_loss_data</span> <span class="o">=</span> <span class="n">Store_Accuracy_and_Loss</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
                                                                    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;training&#39;</span><span class="p">,</span>
                                                                    <span class="n">scope</span> <span class="o">=</span> <span class="s1">&#39;pretraining&#39;</span><span class="p">)</span>
    <span class="n">store_validation_accuracy_and_loss_data</span> <span class="o">=</span> <span class="n">Store_Accuracy_and_Loss</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
                                                                    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;validation&#39;</span><span class="p">,</span>
                                                                    <span class="n">scope</span> <span class="o">=</span> <span class="s1">&#39;pretraining&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plot_flag</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax_arr</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">set_window_title</span><span class="p">(</span><span class="s1">&#39;Pretraining&#39;</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">epoch_index_to_plot</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pretraining_global_fragment</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">list_of_global_fragments</span><span class="o">.</span><span class="n">global_fragments</span><span class="p">,</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Pretraining network&#39;</span><span class="p">)):</span>
        <span class="n">net</span><span class="p">,</span> <span class="n">ratio_of_pretrained_images</span><span class="p">,</span> <span class="n">global_epoch</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pre_train_global_fragment</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
                                                                            <span class="n">pretraining_global_fragment</span><span class="p">,</span>
                                                                            <span class="n">list_of_fragments</span><span class="p">,</span>
                                                                            <span class="n">global_epoch</span><span class="p">,</span>
                                                                            <span class="n">check_for_loss_plateau</span><span class="p">,</span>
                                                                            <span class="n">store_accuracy_and_error</span><span class="p">,</span>
                                                                            <span class="n">save_summaries</span><span class="p">,</span> <span class="n">store_training_accuracy_and_loss_data</span><span class="p">,</span>
                                                                            <span class="n">store_validation_accuracy_and_loss_data</span><span class="p">,</span>
                                                                            <span class="n">print_flag</span> <span class="o">=</span> <span class="n">print_flag</span><span class="p">,</span>
                                                                            <span class="n">plot_flag</span> <span class="o">=</span> <span class="n">plot_flag</span><span class="p">,</span>
                                                                            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">BATCH_SIZE_IDCNN</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ratio_of_pretrained_images</span> <span class="o">&gt;</span> <span class="n">MAX_RATIO_OF_PRETRAINED_IMAGES</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;pre-training ended: The network has been pre-trained on more than </span><span class="si">%.4f</span><span class="s2"> of the images in global fragment&quot;</span> <span class="o">%</span><span class="n">MAX_RATIO_OF_PRETRAINED_IMAGES</span><span class="p">)</span>
            <span class="k">break</span>
</div>
    <span class="k">return</span> <span class="n">net</span>

<div class="viewcode-block" id="pre_trainer"><a class="viewcode-back" href="../fingerprint_protocol_cascade.html#pre_trainer.pre_trainer">[docs]</a><span class="k">def</span> <span class="nf">pre_trainer</span><span class="p">(</span><span class="n">old_video</span><span class="p">,</span> <span class="n">video</span><span class="p">,</span> <span class="n">list_of_fragments</span><span class="p">,</span> <span class="n">list_of_global_fragments</span><span class="p">,</span> <span class="n">pretrain_network_params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialises and starts the pretraining (3rd fingerprint protocol)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    old_video : &lt;Video object&gt;</span>
<span class="sd">        an instance of the class :class:`~video.Video`</span>
<span class="sd">    video :&lt;Video object&gt;</span>
<span class="sd">        an instance of the class :class:`~video.Video`</span>
<span class="sd">    list_of_fragments : &lt;ListOfFragments object&gt;</span>
<span class="sd">        an instance of the class :class:`~list_of_fragments.ListOfFragments`</span>
<span class="sd">    list_of_global_fragments : &lt;ListOfGlobalFragments object&gt;</span>
<span class="sd">        an instance of the class</span>
<span class="sd">        :class:`~list_of_global_fragments.ListOfGlobalFragments`</span>
<span class="sd">    pretrain_network_params :  &lt;NetworkParams object&gt;</span>
<span class="sd">        an instance of the class :class:`~network_params.NetworkParams`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#Reset used_for_training and acceptable_for_training flags</span>
    <span class="k">if</span> <span class="n">old_video</span> <span class="ow">and</span> <span class="n">old_video</span><span class="o">.</span><span class="n">first_accumulation_finished</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">list_of_global_fragments</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">roll_back_to</span> <span class="o">=</span> <span class="s1">&#39;fragmentation&#39;</span><span class="p">)</span>
        <span class="n">list_of_fragments</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">roll_back_to</span> <span class="o">=</span> <span class="s1">&#39;fragmentation&#39;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting pretraining. Checkpoints will be stored in </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">video</span><span class="o">.</span><span class="n">pretraining_folder</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">video</span><span class="o">.</span><span class="n">tracking_with_knowledge_transfer</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Performing knowledge transfer from </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">video</span><span class="o">.</span><span class="n">knowledge_transfer_model_folder</span><span class="p">)</span>
        <span class="n">pretrain_network_params</span><span class="o">.</span><span class="n">knowledge_transfer_folder</span> <span class="o">=</span> <span class="n">video</span><span class="o">.</span><span class="n">knowledge_transfer_model_folder</span>
    <span class="c1">#start pretraining</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Start pretraining&quot;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">pre_train</span><span class="p">(</span><span class="n">video</span><span class="p">,</span> <span class="n">list_of_fragments</span><span class="p">,</span>
                    <span class="n">list_of_global_fragments</span><span class="p">,</span>
                    <span class="n">pretrain_network_params</span><span class="p">,</span>
                    <span class="n">store_accuracy_and_error</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="n">check_for_loss_plateau</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="n">save_summaries</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="n">print_flag</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span></div>
                    <span class="n">plot_flag</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2018, Champalimaud Center for the Unknown.
      </li>
      <li>
      Last updated on May 02, 2018.
      </li>
      <li>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.7.0.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>